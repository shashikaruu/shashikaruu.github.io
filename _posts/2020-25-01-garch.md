---
title: "States and Panic: Improving Volatility Forecasting with Machine Learning"
date: 2018-01-28
tags: [machine learning, history, time series]
header:
excerpt: "Machine Learning, History, Time Series"
---

Dynamic volatility plays an important role in modern financial time series. the application of forecasting conditional variance is essential for investors to make decisions such as risk assessment, leverage effects evaluation and the pricing of derivative securities.

The following outlines how we can incorporate straight-forward machine learning techniques into existing time-series econometrics, to significantly improve forecasting accuracy.

## Forecasting Volatility

I employ the conditional variances of daily logarithmic rates of return of the Australia All Ordinates (Live) Index. Here, I compute the daily realized variances from the 5-minute log-returns of the Index.

```r
library(fImport)
library(timeDate)
library(FinTS)
library(ccgarch)
library(vars)
library(rugarch)

load("AORD.RData")
plot.ts(AORD)

```


![svg]({{ site.url }}/images/data.png)

To tests for forecasting performance, I'll perform a rolling sample forecasting exercise of a 5-day-ahead conditional volatility forecasts. The main criteria I'll use is the Root Mean Square Prediction Error (RMPSE).

## The Standard MODEL

```r
R Code for autocorrelation functions
```

The autocorrelation functions for log returns indicated several potential autocorrelations including at lag 5 and lag 9. Information Criterion (IC) reveals that there is potential for log returns autocorrelation up to 5 lags.

For realised volatility, the data exhibits strong persistence in its autocorrelation function. IC reveals that is potential for a up to 28 lags in realised volatility, which is likely due to the ARCH effects.

Initial tests suggest modelling the data through an AR-GARCH framework, starting with an AR(1), GARCH(1,1) model. We then explore variations around this model, to see which achieves the lowest RMPSE.

![svg]({{ site.url }}/images/acf.png)

Findings

* Models with more than one AR terms achieve poorer forecasts, compared to the AR(1) models.
* Models incorporating student-t distributions achieve better
forecasts, with lower RMSPE.
* While ARCH tests (in the previous page) has shown that the ARCH effects are sufficiently accounted for in the ARCH(1) models, adding an additional lag (ARCH(2)) achieves a better forecast outcome.

We also modify the algorithm to run two simultaneous models and forecasts at the same time: the AR(1) and GARCH(1,2) under normal distribution and student t distribution. We then take the average sigma forecasts and calculated the RMSPE based on these. The output shows that the model fails to perform with a lower RMPSE compared to the AR(1) GARCH(1,2) student t distribution.

Based on the output, we move forward with the AR(1) GARCH (1,2) under a student t distribution, as it achieves the lowest RMSPE amongst the base models.

The following outlines an output of the model.

```r
R Code for model
```

BASELINE OUTPUT [RESULTS]

## AUXILIARY DATASETS: MODELLING STATES AND PANIC

We explore adding in three external variables that could improve the forecast accuracy:
* **Business Days Off Structural Dummy** - a dummy variable of trading days whose last trading period, was more than 1 day in the past. This structural dummy variable accounts for the accumulation of news shocks across non-trading days (e.g. weekends, public holidays) that may affect the volatility of returns on the trading day itself.
* **Google Trend data for financial panic** - the data output of Google Trend ranking data for number of news headlines that use the word “recession.” This data set intends to capture the effects of self-induced states of
panic from reporting bad news of “recession”, and tests whether it is a good forecasting variable for future volatility. The Google Trend data is a weekly data set; we transformed it into a daily dataset, by taking the last day’s or (if data does not exist) last week’s Google new headline’s ranking for “recession.” We then take the log difference between yesterday’s google ranking and the previous day’s google ranking. This capture changes in news that may induce panic in the financial market.
* **Volatility States Structural Dummy** - this structural dummy variable accounts for potential existence of different volatility states. Using a k-means clustering, we segment out the realised into two different sets, a “high volatility states” and a “low volatility states”,
based on their realised volatility.
However, the k-means data output is not revelational in itself, and using contemporaneous realisation of k-means volatility categories is not an ideal variable for forecast. In order to ensure that it is a genuine forecast variable, we construct a dummy variable of whether a “high volatility” state occurred in the past T number of
days (excluding the current day). For the volatility state structural dummy variable, we use T=19 days. In many ways, this is a `cheap` way to incorporate some of the flavours of Markov Regime Switching models (where we model the probability of being in different states), but use a non-parametric method to recover these states (i.e. k-means clustering).

The following outlines a time series plot of the three external regressors.

```r
R code for Image
```
![svg]({{ site.url }}/images/extreg.png)

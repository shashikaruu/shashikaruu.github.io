---
title: "States and Panic: Improving Volatility Forecasting with Machine Learning"
date: 2018-01-28
tags: [machine learning, history, time series]
header:
excerpt: "Machine Learning, History, Time Series"
---

Dynamic volatility plays an important role in modern financial time series. the application of forecasting conditional variance is essential for investors to make decisions such as risk assessment, leverage effects evaluation and the pricing of derivative securities.

The following outlines how we can incorporate straight-forward machine learning techniques into existing time-series econometrics, to significantly improve forecasting accuracy.

## Forecasting Volatility

I employ the conditional variances of daily logarithmic rates of return of the Australia All Ordinates (Live) Index. Here, I compute the daily realized variances from the 5-minute log-returns of the Index.

```r
library(fImport)
library(timeDate)
library(FinTS)
library(ccgarch)
library(vars)
library(rugarch)

load("AORD.RData")
plot.ts(AORD)

```


![svg]({{ site.url }}/images/data.png)

To tests for forecasting performance, I'll perform a rolling sample forecasting exercise of a 5-day-ahead conditional volatility forecasts. The main criteria I'll use is the Root Mean Square Prediction Error (RMPSE).

## The Standard MODEL

```r
R Code for autocorrelation functions
```
![svg]({{ site.url }}/images/acf.png)

The autocorrelation functions for log returns indicated several potential autocorrelations including at lag 5 and lag 9. Information Criterion (IC) reveals that there is potential for log returns autocorrelation up to 5 lags.

For realised volatility, the data exhibits strong persistence in its autocorrelation function. IC reveals that is potential for a up to 28 lags in realised volatility, which is likely due to the ARCH effects.

Initial tests suggest modelling the data through an AR-GARCH framework, starting with an AR(1), GARCH(1,1) model. We then explore variations around this model, to see which achieves the lowest RMPSE.

Baseline Model Variation  | RMSPE | MAPE
------------- | ------------- | -------------
AR(1), GARCH(1,1) - normal dist. | 0.000070000 | 0.0000433000
AR(5), GARCH(1,1) - normal dist. | 0.0000704000 | 0.0000436000
AR(10), GARCH(1,1) - normal dist. | 0.0000702951 | 0.0000437179
AR(1), GARCH(1,2) - normal dist. | 0.0000699743 | 0.0000433816
AR(1), GARCH(1,1) - std dist. | 0.0000696978 | 0.0000435623
AR(5), GARCH(1,1) - std dist. | 0.0000700999 | 0.0000437495
Average sigma forecast of AR(1),
GARCH(1,2) - std dist. And AR(1),
GARCH(1,2) - norm dist. | 0.0000697428 | 0.0000433816
**AR(1), GARCH(1,2) - std dist.** | **0.0000696970** | **0.0000435249**


Findings

* Models with more than one AR terms achieve poorer forecasts, compared to the AR(1) models.
* Models incorporating student-t distributions achieve better
forecasts, with lower RMSPE.
* While ARCH tests (in the previous page) has shown that the ARCH effects are sufficiently accounted for in the ARCH(1) models, adding an additional lag (ARCH(2)) achieves a better forecast outcome.

We also modify the algorithm to run two simultaneous models and forecasts at the same time: the AR(1) and GARCH(1,2) under normal distribution and student t distribution. We then take the average sigma forecasts and calculated the RMSPE based on these. The output shows that the model fails to perform with a lower RMPSE compared to the AR(1) GARCH(1,2) student t distribution.

Based on the output, we move forward with the AR(1) GARCH (1,2) under a student t distribution, as it achieves the lowest RMSPE amongst the base models.

The following outlines an output of the model.

```r
R Code for model
```

BASELINE OUTPUT [RESULTS]

## AUXILIARY DATASETS: MODELLING STATES AND PANIC

We explore adding in three external variables that could improve the forecast accuracy:
* **Business Days Off Structural Dummy** - a dummy variable of trading days whose last trading period, was more than 1 day in the past. This structural dummy variable accounts for the accumulation of news shocks across non-trading days (e.g. weekends, public holidays) that may affect the volatility of returns on the trading day itself.
* **Google Trend data for financial panic** - the data output of Google Trend ranking data for number of news headlines that use the word “recession.” This data set intends to capture the effects of self-induced states of
panic from reporting bad news of “recession”, and tests whether it is a good forecasting variable for future volatility. The Google Trend data is a weekly data set; we transformed it into a daily dataset, by taking the last day’s or (if data does not exist) last week’s Google new headline’s ranking for “recession.” We then take the log difference between yesterday’s google ranking and the previous day’s google ranking. This capture changes in news that may induce panic in the financial market.
* **Volatility States Structural Dummy** - this structural dummy variable accounts for potential existence of different volatility states. Using a k-means clustering, we segment out the realised into two different sets, a “high volatility states” and a “low volatility states”,
based on their realised volatility.
However, the k-means data output is not revelational in itself, and using contemporaneous realisation of k-means volatility categories is not an ideal variable for forecast. In order to ensure that it is a genuine forecast variable, we construct a dummy variable of whether a “high volatility” state occurred in the past T number of
days (excluding the current day). For the volatility state structural dummy variable, we use T=19 days. In many ways, this is a **cheap** way to incorporate some of the flavours of Markov Regime Switching models (where we model the probability of being in different states) through a computationally easier, non-parametric method (i.e. k-means clustering the volatility states).

The following outlines a time series plot of the three external regressors.

```r
R code for Image
```
![svg]({{ site.url }}/images/extreg.png)

## MODIFIED MODEL RESULTS

The following outlines output of modelling the AR(1) GARCH(1,2) model, varying the external regressors. The data shows that there are significant improvements to the RMSPE, when accounting for external regressors.

TEST RESULTS

The data also shows that the external regressors are each
statistically significant. In particular, the log difference google
trends ranking is a particularly strong predictor of future
variance (with a coefficient of 0.000011). The remaining
structural dummy variables show also some effects on realised
variances (with a coefficient of 0.000004 for volatility states
structural dummies and 0.000005 for the business days off
dummies). It is important to note that by construction, these
variables are representing lagged information, and not
contemporaneous realisations on the trading day itself.


Given the findings of the test statistics, we explore variations in the model for different types of GARCH models that may take into account the non-normality or potential asymmetry in the data.

## INCORPORATING ASYMMETRY

We explore a number of GARCH models that attempt to account for the
asymmetric distributions in the model AR(1), GARCH(1,2) - std dist. 3 variables {dayoff struct. dummy, volatility states dummy & log diff Google trend}. In particular we use gjrGARCH, eGARCH and IGARCH to attempt to measure leverage effects or asymmetric attributes in the realisation of variances.

The model shows that the eGARCH outperforms all other modifications
and the standard GARCH model, achieving a RMPSE of 0.0000455708.
Test statistics (on the following page show that):
 * The effects of the external regressors are amplified under the
eGARCH’s exponential form. In particular, the google rankings
show significant and strong effects on realised volatility.
*  We do not reject null that residuals and residuals-squared are
independent and identically distributed (in the Box-Pierce and
Box-Ljung test). The tests suggest autocorrelation is sufficiently
modelled for.
* ARCH tests shows that we do not reject the null that there is
further ARCH effects, indicating ARCH effects are sufficiently
modelled for
* Of note, the model also does not reject the null of the Jacque-
Bera tests indicating the residuals display a normal distribution.

QQ-plot and plot of the residuals’ distributions shows an
improvement to model these distributions.
